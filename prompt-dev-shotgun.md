## ROLE & PRIMARY GOAL:
You are a "Robotic Senior Software Engineer AI". Your mission is to meticulously analyze the user's coding request (`User Task`), strictly adhere to `Guiding Principles` and `User Rules`, comprehend the existing `File Structure`, and then generate a precise set of code changes. Your *sole and exclusive output* must be a single `git diff` formatted text. Zero tolerance for any deviation from the specified output format.

---

## INPUT SECTIONS OVERVIEW:
1.  `User Task`: The user's coding problem or feature request.
2.  `Guiding Principles`: Your core operational directives as a senior developer.
3.  `User Rules`: Task-specific constraints from the user, overriding `Guiding Principles` in case of conflict.
4.  `Output Format & Constraints`: Strict rules for your *only* output: the `git diff` text.
5.  `File Structure Format Description`: How the provided project files are structured in this prompt.
6.  `File Structure`: The current state of the project's files.

---

## 1. User Task
Tarefa 1

---

## 2. Guiding Principles (Your Senior Developer Logic)

### A. Analysis & Planning (Internal Thought Process - Do NOT output this part):
1.  **Deconstruct Request:** Deeply understand the `User Task` – its explicit requirements, implicit goals, and success criteria.
2.  **Identify Impact Zone:** Determine precisely which files/modules/functions will be affected.
3.  **Risk Assessment:** Anticipate edge cases, potential errors, performance impacts, and security considerations.
4.  **Assume with Reason:** If ambiguities exist in `User Task`, make well-founded assumptions based on best practices and existing code context. Document these assumptions internally if complex.
5.  **Optimal Solution Path:** Briefly evaluate alternative solutions, selecting the one that best balances simplicity, maintainability, readability, and consistency with existing project patterns.
6.  **Plan Changes:** Before generating diffs, mentally (or internally) outline the specific changes needed for each affected file.

### B. Code Generation & Standards:
*   **Simplicity & Idiomatic Code:** Prioritize the simplest, most direct solution. Write code that is idiomatic for the language and aligns with project conventions (inferred from `File Structure`). Avoid over-engineering.
*   **Respect Existing Architecture:** Strictly follow the established project structure, naming conventions, and coding style.
*   **Type Safety:** Employ type hints/annotations as appropriate for the language.
*   **Modularity:** Design changes to be modular and reusable where sensible.
*   **Documentation:**
    *   Add concise docstrings/comments for new public APIs, complex logic, or non-obvious decisions.
    *   Update existing documentation if changes render it inaccurate.
*   **Logging:** Introduce logging for critical operations or error states if consistent with the project's logging strategy.
*   **No New Dependencies:** Do NOT introduce external libraries/dependencies unless explicitly stated in `User Task` or `User Rules`.
*   **Atomicity of Changes (Hunks):** Each distinct change block (hunk in the diff output) should represent a small, logically coherent modification.
*   **Testability:** Design changes to be testable. If a testing framework is evident in `File Structure` or mentioned in `User Rules`, ensure new code is compatible.

---

## 3. User Rules
Regra 1
*(These are user-provided, project-specific rules or task constraints. They take precedence over `Guiding Principles`.)*

---

## 4. Output Format & Constraints (MANDATORY & STRICT)

Your **ONLY** output will be a single, valid `git diff` formatted text, specifically in the **unified diff format**. No other text, explanations, or apologies are permitted.

### Git Diff Format Structure:
*   If no changes are required, output an empty string.
*   For each modified, newly created, or deleted file, include a diff block. Multiple file diffs are concatenated directly.

### File Diff Block Structure:
A typical diff block for a modified file looks like this:
```diff
diff --git a/relative/path/to/file.ext b/relative/path/to/file.ext
index <hash_old>..<hash_new> <mode>
--- a/relative/path/to/file.ext
+++ b/relative/path/to/file.ext
@@ -START_OLD,LINES_OLD +START_NEW,LINES_NEW @@
 context line (unchanged)
-old line to be removed
+new line to be added
 another context line (unchanged)
```

*   **`diff --git a/path b/path` line:**
    *   Indicates the start of a diff for a specific file.
    *   `a/path/to/file.ext` is the path in the "original" version.
    *   `b/path/to/file.ext` is the path in the "new" version. Paths are project-root-relative, using forward slashes (`/`).
*   **`index <hash_old>..<hash_new> <mode>` line (Optional Detail):**
    *   This line provides metadata about the change. While standard in `git diff`, if generating precise hashes and modes is overly complex for your internal model, you may omit this line or use placeholder values (e.g., `index 0000000..0000000 100644`). The `---`, `+++`, and `@@` lines are the most critical for applying the patch.
*   **`--- a/path/to/file.ext` line:**
    *   Specifies the original file. For **newly created files**, this should be `--- /dev/null`.
*   **`+++ b/path/to/file.ext` line:**
    *   Specifies the new file. For **deleted files**, this should be `+++ /dev/null`. For **newly created files**, this is `+++ b/path/to/new_file.ext`.
*   **Hunk Header (`@@ -START_OLD,LINES_OLD +START_NEW,LINES_NEW @@`):**
    *   `START_OLD,LINES_OLD`: 1-based start line and number of lines from the original file affected by this hunk.
        *   For **newly created files**, this is `0,0`.
        *   For hunks that **only add lines** (no deletions from original), `LINES_OLD` is `0`. (e.g., `@@ -50,0 +51,5 @@` means 5 lines added after original line 50).
    *   `START_NEW,LINES_NEW`: 1-based start line and number of lines in the new file version affected by this hunk.
        *   For **deleted files** (where the entire file is deleted), this is `0,0` for the `+++ /dev/null` part.
        *   For hunks that **only delete lines** (no additions), `LINES_NEW` is `0`. (e.g., `@@ -25,3 +25,0 @@` means 3 lines deleted starting from original line 25).
*   **Hunk Content:**
    *   Lines prefixed with a space (` `) are context lines (unchanged).
    *   Lines prefixed with a minus (`-`) are lines removed from the original file.
    *   Lines prefixed with a plus (`+`) are lines added to the new file.
    *   Include at least 3 lines of unchanged context around changes, where available. If changes are at the very beginning or end of a file, or if hunks are very close, fewer context lines are acceptable as per standard unified diff practice.

### Specific Cases:
*   **Newly Created Files:**
    ```diff
    diff --git a/relative/path/to/new_file.ext b/relative/path/to/new_file.ext
    new file mode 100644
    index 0000000..<hash_new_placeholder>
    --- /dev/null
    +++ b/relative/path/to/new_file.ext
    @@ -0,0 +1,LINES_IN_NEW_FILE @@
    +line 1 of new file
    +line 2 of new file
    ...
    ```
    *(The `new file mode` and `index` lines should be included. Use `100644` for regular files. For the hash in the `index` line, a placeholder like `abcdef0` is acceptable if the actual hash cannot be computed.)*

*   **Deleted Files:**
    ```diff
    diff --git a/relative/path/to/deleted_file.ext b/relative/path/to/deleted_file.ext
    deleted file mode <mode_old_placeholder>
    index <hash_old_placeholder>..0000000
    --- a/relative/path/to/deleted_file.ext
    +++ /dev/null
    @@ -1,LINES_IN_OLD_FILE +0,0 @@
    -line 1 of old file
    -line 2 of old file
    ...
    ```
    *(The `deleted file mode` and `index` lines should be included. Use a placeholder like `100644` for mode and `abcdef0` for hash if actual values are unknown.)*

*   **Untouched Files:** Do NOT include any diff output for files that have no changes.

### General Constraints on Generated Code:
*   **Minimal & Precise Changes:** Generate the smallest, most targeted diff that correctly implements the `User Task` per all rules.
*   **Preserve Integrity:** Do not break existing functionality unless the `User Task` explicitly requires it. The codebase should remain buildable/runnable.
*   **Leverage Existing Code:** Prefer modifying existing files over creating new ones, unless a new file is architecturally justified or required by `User Task` or `User Rules`.

---

## 5. File Structure Format Description
The `File Structure` (provided in the next section) is formatted as follows:
1.  An initial project directory tree structure (e.g., generated by `tree` or similar).
2.  Followed by the content of each file, using an XML-like structure:
    <file path="RELATIVE/PATH/TO/FILE">
    (File content here)
    </file>
    The `path` attribute contains the project-root-relative path, using forward slashes (`/`).
    File content is the raw text of the file. Each file block is separated by a newline.

---

## 6. File Structure
shotgun-terminal\
├── shotgun_terminal
│   ├── __init__.py
│   ├── cli.py
│   ├── config.py
│   ├── context_generator.py
│   ├── file_selector.py
│   ├── prompts.py
│   ├── settings.py
│   ├── translator.py
│   ├── tree_generator.py
│   └── user_input.py
├── shotgun_terminal.egg-info
│   ├── dependency_links.txt
│   ├── entry_points.txt
│   ├── PKG-INFO
│   ├── requires.txt
│   ├── SOURCES.txt
│   └── top_level.txt
├── pyproject.toml
├── README.md
├── requirements.txt
└── setup.py

<file path="shotgun_terminal/__init__.py">
"""Shotgun Terminal - Generate comprehensive project context for LLM workflows."""

__version__ = "0.1.0"
__author__ = "Shotgun Code Team"
</file>
<file path="shotgun_terminal/cli.py">
#!/usr/bin/env python3

import click
import os
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt, Confirm
from rich.table import Table
import inquirer

from .prompts import process_template
from .file_selector import FileSelector
from .context_generator import ContextGenerator
from .user_input import UserInputCollector
from .settings import SettingsManager
from .config import ConfigManager
from .translator import TranslationService

console = Console()

@click.command()
@click.option('--directory', '-d', type=click.Path(exists=True, file_okay=False, dir_okay=True), 
              help='Project directory to analyze')
@click.option('--output', '-o', type=click.Path(), help='Output file path (default: shotgun_context.txt)')
@click.option('--prompt-type', '-p', type=click.Choice(['dev', 'architect', 'bug']), 
              help='Type of prompt to generate')
@click.option('--config', is_flag=True, help='Configure API settings for translation')
@click.option('--quick-setup', is_flag=True, help='Quick setup with test credentials')
def main(directory, output, prompt_type, config, quick_setup):
    """Shotgun Terminal - Generate comprehensive project context for LLM workflows."""
    
    console.print(Panel.fit(
        "[bold blue]🔫 Shotgun Terminal[/bold blue]\n"
        "Generate comprehensive project context for LLM workflows",
        border_style="blue"
    ))
    
    # Handle configuration commands
    if config or quick_setup:
        config_manager = ConfigManager()
        
        if quick_setup:
            config_manager.quick_setup()
        else:
            config_manager.configure_api()
        
        return
    
    # Initialize components
    settings = SettingsManager()
    user_input = UserInputCollector()
    translator = TranslationService()
    
    # Step 1: Select project directory
    if not directory:
        directory = select_directory(settings)
    
    console.print(f"\n[green]✓[/green] Selected directory: {directory}")
    settings.set_last_used_directory(directory)
    
    # Step 2: Collect user task
    console.print("\n" + "="*60)
    user_task = user_input.collect_user_task()
    console.print(f"\n[green]✓[/green] Task collected")
    
    # Step 3: Collect custom rules
    console.print("\n" + "="*60)
    custom_rules = user_input.collect_custom_rules()
    console.print(f"\n[green]✓[/green] Custom rules configured")
    
    # Step 4: Translate task and rules to English (if enabled)
    if settings.is_translation_enabled() and translator.is_configured():
        console.print("\n" + "="*60)
        console.print("[yellow]Translating to English...[/yellow]")
        
        translated_task = translator.translate_to_english(user_task, "task")
        if translated_task:
            user_task = translated_task
        
        translated_rules = translator.translate_to_english(custom_rules, "rules")
        if translated_rules:
            custom_rules = translated_rules
        
        console.print(f"\n[green]✓[/green] Translation completed")
    elif settings.is_translation_enabled():
        console.print("\n[yellow]Translation enabled but API not configured. Use 'shotgun-terminal --config' to set up.[/yellow]")
    
    # Step 5: Interactive file selection
    console.print("\n" + "="*60)
    file_selector = FileSelector(directory)
    included_files, ignore_patterns = file_selector.interactive_selection()
    console.print(f"\n[green]✓[/green] Files selected")
    
    # Step 6: Select prompt type
    if not prompt_type:
        console.print("\n" + "="*60)
        prompt_type = select_prompt_type()
    
    # Step 7: Generate output file path
    if not output:
        output = f"shotgun_context_{prompt_type}.txt"
    
    # Step 8: Generate context
    console.print("\n" + "="*60)
    console.print(f"[yellow]Generating context...[/yellow]")
    generate_context(directory, included_files, ignore_patterns, prompt_type, output, user_task, custom_rules)
    
    console.print(f"\n[bold green]🎉 Success![/bold green]")
    console.print(f"[green]✓[/green] Context generated successfully!")
    console.print(f"[green]✓[/green] Output saved to: {output}")
    
    # Show final summary
    show_summary(output, user_task, len(included_files))


def select_directory(settings):
    """Interactive directory selection."""
    current_dir = os.getcwd()
    last_used = settings.get_last_used_directory()
    
    console.print(f"\n[yellow]Current directory:[/yellow] {current_dir}")
    if last_used and last_used != current_dir:
        console.print(f"[blue]Last used directory:[/blue] {last_used}")
    
    choices = ["Use current directory"]
    if last_used and last_used != current_dir and os.path.exists(last_used):
        choices.append("Use last used directory")
    choices.append("Enter custom path")
    
    choice = inquirer.list_input("Select directory", choices=choices)
    
    if choice == "Use current directory":
        return current_dir
    elif choice == "Use last used directory":
        return last_used
    else:
        directory = Prompt.ask("Enter project directory path")
        
        if not os.path.exists(directory):
            console.print(f"[red]Error:[/red] Directory {directory} does not exist")
            return select_directory(settings)
        
        return directory


def select_prompt_type():
    """Interactive prompt type selection."""
    console.print("\n[yellow]Select prompt type:[/yellow]")
    
    table = Table(show_header=True, header_style="bold magenta")
    table.add_column("Type", style="dim", width=12)
    table.add_column("Description")
    
    table.add_row("dev", "General development assistance and code analysis")
    table.add_row("architect", "Architecture review and system design")
    table.add_row("bug", "Bug analysis and debugging assistance")
    
    console.print(table)
    
    questions = [
        inquirer.List('prompt_type',
                     message="Choose prompt type",
                     choices=[
                         ('dev - General development assistance', 'dev'),
                         ('architect - Architecture review', 'architect'), 
                         ('bug - Bug analysis and debugging', 'bug')
                     ])
    ]
    
    answers = inquirer.prompt(questions)
    return answers['prompt_type']


def generate_context(directory, included_files, ignore_patterns, prompt_type, output_file, user_task, custom_rules):
    """Generate context using internal Python implementation."""
    
    try:
        # Create context generator
        generator = ContextGenerator(directory)
        
        # Show file statistics
        stats = generator.get_file_stats(included_files, ignore_patterns)
        console.print(f"[blue]Files to process: {stats['total_files']}[/blue]")
        console.print(f"[blue]Total size: {stats['total_size'] / 1024:.1f} KB[/blue]")
        
        if stats['large_files']:
            console.print(f"[yellow]Large files (will be skipped): {len(stats['large_files'])}[/yellow]")
        
        if stats['binary_files']:
            console.print(f"[yellow]Binary files (will be summarized): {len(stats['binary_files'])}[/yellow]")
        
        # Generate project tree
        project_tree = generator.generate_project_tree(included_files, ignore_patterns)
        
        # Generate context
        context = generator.generate_context(included_files, ignore_patterns, 'claude-xml')
        
        # Process template with user inputs
        final_output = process_template(prompt_type, user_task, custom_rules, context, project_tree)
        
        # Write to output file
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(final_output)
            
    except Exception as e:
        console.print(f"[red]Error generating context:[/red] {e}")
        raise


def show_summary(output_file, user_task, file_count):
    """Show final summary of the generated context."""
    console.print(Panel.fit(
        f"[bold green]📄 Context Summary[/bold green]\n\n"
        f"[blue]Task:[/blue] {user_task[:100]}{'...' if len(user_task) > 100 else ''}\n"
        f"[blue]Files processed:[/blue] {file_count}\n"
        f"[blue]Output file:[/blue] {output_file}\n\n"
        f"[dim]You can now copy the content from {output_file} and paste it into your preferred LLM interface.[/dim]",
        border_style="green"
    ))


if __name__ == '__main__':
    main()
</file>
<file path="shotgun_terminal/config.py">
"""Configuration management for API settings."""

from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt, Confirm
from rich.table import Table
import inquirer

from .settings import SettingsManager
from .translator import TranslationService

console = Console()

class ConfigManager:
    """Manage API configuration settings."""
    
    def __init__(self):
        self.settings = SettingsManager()
        self.translator = TranslationService()
    
    def configure_api(self):
        """Interactive API configuration."""
        console.print(Panel.fit(
            "[bold cyan]🔧 API Configuration[/bold cyan]\n"
            "Configure OpenAI-compatible API for translation",
            border_style="cyan"
        ))
        
        # Show current settings
        self._show_current_settings()
        
        # Configuration menu
        while True:
            action = inquirer.list_input(
                "Choose configuration action",
                choices=[
                    'Configure API credentials',
                    'Test API connection',
                    'Toggle translation on/off',
                    'View current settings',
                    'Reset to defaults',
                    'Exit configuration'
                ]
            )
            
            if action == 'Configure API credentials':
                self._configure_credentials()
            elif action == 'Test API connection':
                self._test_connection()
            elif action == 'Toggle translation on/off':
                self._toggle_translation()
            elif action == 'View current settings':
                self._show_current_settings()
            elif action == 'Reset to defaults':
                self._reset_to_defaults()
            elif action == 'Exit configuration':
                break
    
    def _configure_credentials(self):
        """Configure API credentials."""
        console.print("\n[yellow]Configure API Credentials[/yellow]")
        
        current_settings = self.settings.get_api_settings()
        
        # API Key
        current_key = current_settings.get('api_key', '')
        masked_key = f"{current_key[:8]}...{current_key[-4:]}" if len(current_key) > 12 else "Not set"
        console.print(f"[blue]Current API Key:[/blue] {masked_key}")
        
        new_key = Prompt.ask("Enter API Key", default=current_key if current_key else "")
        
        # Base URL
        current_url = current_settings.get('base_url', '')
        console.print(f"[blue]Current Base URL:[/blue] {current_url or 'Not set'}")
        
        new_url = Prompt.ask("Enter Base URL", default=current_url if current_url else "https://copilot.quantmind.com.br")
        
        # Model
        current_model = current_settings.get('model', 'gpt-4.1')
        console.print(f"[blue]Current Model:[/blue] {current_model}")
        
        new_model = Prompt.ask("Enter Model", default=current_model)
        
        # Enable translation
        current_enabled = current_settings.get('enable_translation', True)
        enable_translation = Confirm.ask("Enable translation?", default=current_enabled)
        
        # Save settings
        if new_key and new_url:
            self.settings.set_api_settings(new_key, new_url, new_model, enable_translation)
            console.print("[green]✓[/green] API settings saved successfully!")
            
            # Reinitialize translator with new settings
            self.translator._initialize_client()
            
            # Test connection
            if Confirm.ask("Test connection now?", default=True):
                self._test_connection()
        else:
            console.print("[red]Error:[/red] API Key and Base URL are required")
    
    def _test_connection(self):
        """Test API connection."""
        console.print("\n[yellow]Testing API Connection[/yellow]")
        
        if not self.translator.is_configured():
            console.print("[red]Error:[/red] API not configured. Please configure credentials first.")
            return
        
        if self.translator.test_connection():
            console.print("[green]✓[/green] API connection successful!")
            
            # Test translation
            if Confirm.ask("Test translation functionality?", default=True):
                test_text = "Olá, este é um teste de tradução."
                console.print(f"[blue]Testing translation:[/blue] {test_text}")
                
                translated = self.translator.translate_to_english(test_text, "test")
                if translated:
                    console.print(f"[green]✓[/green] Translation result: {translated}")
                else:
                    console.print("[red]✗[/red] Translation failed")
        else:
            console.print("[red]✗[/red] API connection failed!")
    
    def _toggle_translation(self):
        """Toggle translation on/off."""
        current_enabled = self.settings.is_translation_enabled()
        new_enabled = not current_enabled
        
        self.settings.set_translation_enabled(new_enabled)
        
        status = "enabled" if new_enabled else "disabled"
        console.print(f"[green]✓[/green] Translation {status}")
    
    def _show_current_settings(self):
        """Show current API settings."""
        console.print("\n[blue]Current API Settings:[/blue]")
        
        settings = self.settings.get_api_settings()
        
        table = Table(show_header=True, header_style="bold magenta")
        table.add_column("Setting", style="dim", width=20)
        table.add_column("Value")
        
        # Mask API key for security
        api_key = settings.get('api_key', '')
        masked_key = f"{api_key[:8]}...{api_key[-4:]}" if len(api_key) > 12 else "Not configured"
        
        table.add_row("API Key", masked_key)
        table.add_row("Base URL", settings.get('base_url', 'Not configured'))
        table.add_row("Model", settings.get('model', 'gpt-4.1'))
        table.add_row("Translation Enabled", "Yes" if settings.get('enable_translation', True) else "No")
        table.add_row("Status", "Configured" if self.translator.is_configured() else "Not configured")
        
        console.print(table)
        console.print()
    
    def _reset_to_defaults(self):
        """Reset API settings to defaults."""
        if Confirm.ask("Reset all API settings to defaults? This will remove your credentials.", default=False):
            default_api_settings = self.settings._get_default_settings()["apiSettings"]
            self.settings.set_api_settings(
                default_api_settings["api_key"],
                default_api_settings["base_url"],
                default_api_settings["model"],
                default_api_settings["enable_translation"]
            )
            console.print("[green]✓[/green] Settings reset to defaults")
            
            # Reinitialize translator
            self.translator._initialize_client()
    
    def quick_setup(self):
        """Quick setup with provided test credentials."""
        console.print(Panel.fit(
            "[bold green]🚀 Quick Setup[/bold green]\n"
            "Setting up with test credentials",
            border_style="green"
        ))
        
        # Set up with provided test credentials
        test_api_key = "ck_4c5a9f054475f54d91a17e5e5a0b545c"
        test_base_url = "https://copilot.quantmind.com.br"
        test_model = "gpt-4.1"
        
        self.settings.set_api_settings(test_api_key, test_base_url, test_model, True)
        console.print("[green]✓[/green] Test credentials configured!")
        
        # Reinitialize translator
        self.translator._initialize_client()
        
        # Test connection
        console.print("\n[blue]Testing connection...[/blue]")
        if self.translator.test_connection():
            console.print("[green]✓[/green] Quick setup completed successfully!")
        else:
            console.print("[red]✗[/red] Connection test failed. Please check credentials.")
</file>
<file path="shotgun_terminal/context_generator.py">
"""Context generation module using Python implementation."""

import os
import fnmatch
from pathlib import Path
from rich.console import Console
from .tree_generator import TreeGenerator

console = Console()

class ContextGenerator:
    """Generate project context without external command dependencies."""
    
    def __init__(self, directory):
        self.directory = Path(directory)
        self.max_file_size = 1024 * 1024  # 1MB per file limit
        self.max_total_size = 10 * 1024 * 1024  # 10MB total limit
        self.tree_generator = TreeGenerator(directory)
    
    def generate_context(self, included_files, ignore_patterns, format_type='claude-xml'):
        """Generate context from included files."""
        
        if format_type == 'claude-xml':
            return self._generate_claude_xml_format(included_files, ignore_patterns)
        else:
            return self._generate_default_format(included_files, ignore_patterns)
    
    def _generate_claude_xml_format(self, included_files, ignore_patterns):
        """Generate context in Claude XML format."""
        
        output_lines = []
        total_size = 0
        processed_files = 0
        
        # Start with files directly (no header needed)
        
        for file_path in included_files:
            if self._should_ignore_file(file_path, ignore_patterns):
                continue
                
            full_path = self.directory / file_path
            
            if not full_path.is_file():
                continue
            
            try:
                # Check file size
                file_size = full_path.stat().st_size
                if file_size > self.max_file_size:
                    console.print(f"[yellow]Skipping large file:[/yellow] {file_path} ({file_size} bytes)")
                    continue
                
                # Check total size limit
                if total_size + file_size > self.max_total_size:
                    console.print(f"[yellow]Reached size limit. Processed {processed_files} files.[/yellow]")
                    break
                
                # Read file content
                content = self._read_file_safely(full_path)
                if content is None:
                    continue
                
                # Add to output in Claude XML format
                output_lines.append(f'<file path="{file_path}">')
                output_lines.append(content)
                output_lines.append('</file>')
                output_lines.append('')
                
                total_size += file_size
                processed_files += 1
                
                if processed_files % 10 == 0:
                    console.print(f"[blue]Processed {processed_files} files...[/blue]")
                    
            except Exception as e:
                console.print(f"[red]Error processing {file_path}:[/red] {e}")
                continue
        
        console.print(f"[green]Successfully processed {processed_files} files[/green]")
        return '\n'.join(output_lines)
    
    def _generate_default_format(self, included_files, ignore_patterns):
        """Generate context in default format."""
        
        output_lines = []
        total_size = 0
        processed_files = 0
        
        for file_path in included_files:
            if self._should_ignore_file(file_path, ignore_patterns):
                continue
                
            full_path = self.directory / file_path
            
            if not full_path.is_file():
                continue
            
            try:
                # Check file size
                file_size = full_path.stat().st_size
                if file_size > self.max_file_size:
                    console.print(f"[yellow]Skipping large file:[/yellow] {file_path} ({file_size} bytes)")
                    continue
                
                # Check total size limit
                if total_size + file_size > self.max_total_size:
                    console.print(f"[yellow]Reached size limit. Processed {processed_files} files.[/yellow]")
                    break
                
                # Read file content
                content = self._read_file_safely(full_path)
                if content is None:
                    continue
                
                # Add to output in default format
                output_lines.append(f"--- {file_path} ---")
                output_lines.append(content)
                output_lines.append("")
                
                total_size += file_size
                processed_files += 1
                
                if processed_files % 10 == 0:
                    console.print(f"[blue]Processed {processed_files} files...[/blue]")
                    
            except Exception as e:
                console.print(f"[red]Error processing {file_path}:[/red] {e}")
                continue
        
        console.print(f"[green]Successfully processed {processed_files} files[/green]")
        return '\n'.join(output_lines)
    
    def _should_ignore_file(self, file_path, ignore_patterns):
        """Check if file should be ignored based on patterns."""
        
        for pattern in ignore_patterns:
            if fnmatch.fnmatch(file_path, pattern) or fnmatch.fnmatch(os.path.basename(file_path), pattern):
                return True
                
            # Check if any parent directory matches pattern
            parts = Path(file_path).parts
            for part in parts:
                if fnmatch.fnmatch(part, pattern):
                    return True
        
        return False
    
    def _read_file_safely(self, file_path):
        """Read file content safely with encoding detection."""
        
        # Try different encodings
        encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read()
                
                # Check if it's a binary file (contains null bytes)
                if '\x00' in content:
                    return f"<Binary file: {file_path.suffix} file>"
                
                return content
                
            except UnicodeDecodeError:
                continue
            except Exception as e:
                console.print(f"[red]Error reading {file_path}:[/red] {e}")
                return None
        
        # If all encodings fail, treat as binary
        return f"<Binary file: {file_path.suffix} file>"
    
    def get_file_stats(self, included_files, ignore_patterns):
        """Get statistics about files to be processed."""
        
        stats = {
            'total_files': 0,
            'total_size': 0,
            'file_types': {},
            'large_files': [],
            'binary_files': []
        }
        
        for file_path in included_files:
            if self._should_ignore_file(file_path, ignore_patterns):
                continue
                
            full_path = self.directory / file_path
            
            if not full_path.is_file():
                continue
            
            try:
                file_size = full_path.stat().st_size
                file_ext = full_path.suffix or 'no extension'
                
                stats['total_files'] += 1
                stats['total_size'] += file_size
                stats['file_types'][file_ext] = stats['file_types'].get(file_ext, 0) + 1
                
                if file_size > self.max_file_size:
                    stats['large_files'].append((file_path, file_size))
                
                # Quick binary check
                try:
                    with open(full_path, 'rb') as f:
                        sample = f.read(1024)
                    if b'\x00' in sample:
                        stats['binary_files'].append(file_path)
                except:
                    pass
                    
            except Exception:
                continue
        
        return stats
    
    def generate_project_tree(self, included_files, ignore_patterns):
        """Generate project tree structure."""
        return self.tree_generator.generate_tree(included_files, ignore_patterns)
</file>
<file path="shotgun_terminal/file_selector.py">
"""Interactive file selection module."""

import os
import fnmatch
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.prompt import Confirm, Prompt
import inquirer

console = Console()

class FileSelector:
    """Interactive file selector with ignore pattern support."""
    
    def __init__(self, directory):
        self.directory = Path(directory)
        self.default_ignore_patterns = [
            '*.pyc',
            '__pycache__',
            '.git',
            '.gitignore',
            '*.log',
            'node_modules',
            '.env',
            '*.tmp',
            '.DS_Store',
            'build',
            'dist',
            '*.egg-info'
        ]
    
    def interactive_selection(self):
        """Interactive file selection process."""
        console.print(f"\n[yellow]Analyzing directory:[/yellow] {self.directory}")
        
        # Get all files
        all_files = self._get_all_files()
        
        console.print(f"[blue]Found {len(all_files)} files[/blue]")
        
        # Show file overview
        self._show_file_overview(all_files)
        
        # Configure ignore patterns
        ignore_patterns = self._configure_ignore_patterns()
        
        # Apply ignore patterns
        filtered_files = self._apply_ignore_patterns(all_files, ignore_patterns)
        
        console.print(f"\n[green]Selected {len(filtered_files)} files after filtering[/green]")
        
        # Optional: Manual file review
        if Confirm.ask("Review and modify file selection manually?", default=False):
            filtered_files = self._manual_file_selection(filtered_files)
        
        return filtered_files, ignore_patterns
    
    def _get_all_files(self):
        """Get all files in directory recursively."""
        files = []
        for root, dirs, filenames in os.walk(self.directory):
            # Skip hidden directories
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            
            for filename in filenames:
                if not filename.startswith('.'):
                    file_path = Path(root) / filename
                    rel_path = file_path.relative_to(self.directory)
                    files.append(str(rel_path))
        
        return sorted(files)
    
    def _show_file_overview(self, files):
        """Show overview of files by extension."""
        extensions = {}
        for file in files:
            ext = Path(file).suffix or 'no extension'
            extensions[ext] = extensions.get(ext, 0) + 1
        
        table = Table(title="File Overview by Extension")
        table.add_column("Extension", style="cyan")
        table.add_column("Count", style="magenta")
        
        for ext, count in sorted(extensions.items(), key=lambda x: x[1], reverse=True):
            table.add_row(ext, str(count))
        
        console.print(table)
    
    def _configure_ignore_patterns(self):
        """Configure ignore patterns interactively."""
        console.print(f"\n[yellow]Current ignore patterns:[/yellow]")
        
        for i, pattern in enumerate(self.default_ignore_patterns, 1):
            console.print(f"{i:2}. {pattern}")
        
        # Ask if user wants to modify patterns
        modify = Confirm.ask("\nModify ignore patterns?", default=False)
        
        if not modify:
            return self.default_ignore_patterns.copy()
        
        ignore_patterns = self.default_ignore_patterns.copy()
        
        while True:
            action = inquirer.list_input(
                "Choose action",
                choices=[
                    'Add pattern',
                    'Remove pattern', 
                    'View current patterns',
                    'Done'
                ]
            )
            
            if action == 'Add pattern':
                pattern = Prompt.ask("Enter ignore pattern (e.g., '*.log', 'temp/')")
                if pattern:
                    ignore_patterns.append(pattern)
                    console.print(f"[green]Added:[/green] {pattern}")
            
            elif action == 'Remove pattern':
                if ignore_patterns:
                    questions = [
                        inquirer.Checkbox('patterns',
                                        message="Select patterns to remove",
                                        choices=ignore_patterns)
                    ]
                    answers = inquirer.prompt(questions)
                    for pattern in answers['patterns']:
                        ignore_patterns.remove(pattern)
                        console.print(f"[red]Removed:[/red] {pattern}")
                else:
                    console.print("[yellow]No patterns to remove[/yellow]")
            
            elif action == 'View current patterns':
                console.print(f"\n[yellow]Current patterns:[/yellow]")
                for pattern in ignore_patterns:
                    console.print(f"  • {pattern}")
                console.print()
            
            elif action == 'Done':
                break
        
        return ignore_patterns
    
    def _apply_ignore_patterns(self, files, ignore_patterns):
        """Apply ignore patterns to file list."""
        filtered_files = []
        
        for file in files:
            should_ignore = False
            
            for pattern in ignore_patterns:
                if fnmatch.fnmatch(file, pattern) or fnmatch.fnmatch(os.path.basename(file), pattern):
                    should_ignore = True
                    break
                
                # Check if any parent directory matches pattern
                parts = Path(file).parts
                for part in parts:
                    if fnmatch.fnmatch(part, pattern):
                        should_ignore = True
                        break
                
                if should_ignore:
                    break
            
            if not should_ignore:
                filtered_files.append(file)
        
        return filtered_files
    
    def _manual_file_selection(self, files):
        """Manual file selection interface."""
        console.print(f"\n[yellow]Manual file selection - {len(files)} files[/yellow]")
        
        # Show files in groups for easier selection
        page_size = 20
        selected_files = files.copy()
        
        while True:
            action = inquirer.list_input(
                "Choose action",
                choices=[
                    'View selected files',
                    'Remove files by pattern',
                    'Remove specific files',
                    'Add back files',
                    'Done'
                ]
            )
            
            if action == 'View selected files':
                self._show_file_list(selected_files)
            
            elif action == 'Remove files by pattern':
                pattern = Prompt.ask("Enter pattern to remove (e.g., '*.test.js')")
                if pattern:
                    before_count = len(selected_files)
                    selected_files = [f for f in selected_files 
                                    if not fnmatch.fnmatch(f, pattern)]
                    removed_count = before_count - len(selected_files)
                    console.print(f"[red]Removed {removed_count} files[/red]")
            
            elif action == 'Remove specific files':
                if len(selected_files) > 50:
                    console.print("[yellow]Too many files for individual selection. Use pattern removal instead.[/yellow]")
                else:
                    questions = [
                        inquirer.Checkbox('files',
                                        message="Select files to remove",
                                        choices=selected_files[:50])  # Limit for usability
                    ]
                    answers = inquirer.prompt(questions)
                    for file in answers['files']:
                        selected_files.remove(file)
                    console.print(f"[red]Removed {len(answers['files'])} files[/red]")
            
            elif action == 'Add back files':
                excluded_files = [f for f in files if f not in selected_files]
                if excluded_files:
                    if len(excluded_files) > 50:
                        console.print("[yellow]Too many excluded files. Use pattern matching to add back.[/yellow]")
                        pattern = Prompt.ask("Enter pattern to add back (e.g., '*.py')")
                        if pattern:
                            added_files = [f for f in excluded_files 
                                         if fnmatch.fnmatch(f, pattern)]
                            selected_files.extend(added_files)
                            console.print(f"[green]Added back {len(added_files)} files[/green]")
                    else:
                        questions = [
                            inquirer.Checkbox('files',
                                            message="Select files to add back",
                                            choices=excluded_files)
                        ]
                        answers = inquirer.prompt(questions)
                        selected_files.extend(answers['files'])
                        console.print(f"[green]Added back {len(answers['files'])} files[/green]")
                else:
                    console.print("[yellow]No excluded files to add back[/yellow]")
            
            elif action == 'Done':
                break
        
        return sorted(selected_files)
    
    def _show_file_list(self, files):
        """Show list of files in a formatted way."""
        console.print(f"\n[blue]Selected files ({len(files)}):[/blue]")
        
        for i, file in enumerate(files[:50], 1):  # Show first 50
            console.print(f"{i:3}. {file}")
        
        if len(files) > 50:
            console.print(f"... and {len(files) - 50} more files")
        
        console.print()
</file>
<file path="shotgun_terminal/prompts.py">
"""Prompt templates for different use cases with placeholder support."""

from datetime import datetime

# Git diff output format constraints for dev mode
OUTPUT_FORMAT_CONSTRAINTS_DEV = """## 4. Output Format & Constraints (MANDATORY & STRICT)

Your **ONLY** output will be a single, valid `git diff` formatted text, specifically in the **unified diff format**. No other text, explanations, or apologies are permitted.

### Git Diff Format Structure:
*   If no changes are required, output an empty string.
*   For each modified, newly created, or deleted file, include a diff block. Multiple file diffs are concatenated directly.

### File Diff Block Structure:
A typical diff block for a modified file looks like this:
```diff
diff --git a/relative/path/to/file.ext b/relative/path/to/file.ext
index <hash_old>..<hash_new> <mode>
--- a/relative/path/to/file.ext
+++ b/relative/path/to/file.ext
@@ -START_OLD,LINES_OLD +START_NEW,LINES_NEW @@
 context line (unchanged)
-old line to be removed
+new line to be added
 another context line (unchanged)
```

*   **`diff --git a/path b/path` line:**
    *   Indicates the start of a diff for a specific file.
    *   `a/path/to/file.ext` is the path in the "original" version.
    *   `b/path/to/file.ext` is the path in the "new" version. Paths are project-root-relative, using forward slashes (`/`).
*   **`index <hash_old>..<hash_new> <mode>` line (Optional Detail):**
    *   This line provides metadata about the change. While standard in `git diff`, if generating precise hashes and modes is overly complex for your internal model, you may omit this line or use placeholder values (e.g., `index 0000000..0000000 100644`). The `---`, `+++`, and `@@` lines are the most critical for applying the patch.
*   **`--- a/path/to/file.ext` line:**
    *   Specifies the original file. For **newly created files**, this should be `--- /dev/null`.
*   **`+++ b/path/to/file.ext` line:**
    *   Specifies the new file. For **deleted files**, this should be `+++ /dev/null`. For **newly created files**, this is `+++ b/path/to/new_file.ext`.
*   **Hunk Header (`@@ -START_OLD,LINES_OLD +START_NEW,LINES_NEW @@`):**
    *   `START_OLD,LINES_OLD`: 1-based start line and number of lines from the original file affected by this hunk.
        *   For **newly created files**, this is `0,0`.
        *   For hunks that **only add lines** (no deletions from original), `LINES_OLD` is `0`. (e.g., `@@ -50,0 +51,5 @@` means 5 lines added after original line 50).
    *   `START_NEW,LINES_NEW`: 1-based start line and number of lines in the new file version affected by this hunk.
        *   For **deleted files** (where the entire file is deleted), this is `0,0` for the `+++ /dev/null` part.
        *   For hunks that **only delete lines** (no additions), `LINES_NEW` is `0`. (e.g., `@@ -25,3 +25,0 @@` means 3 lines deleted starting from original line 25).
*   **Hunk Content:**
    *   Lines prefixed with a space (` `) are context lines (unchanged).
    *   Lines prefixed with a minus (`-`) are lines removed from the original file.
    *   Lines prefixed with a plus (`+`) are lines added to the new file.
    *   Include at least 3 lines of unchanged context around changes, where available. If changes are at the very beginning or end of a file, or if hunks are very close, fewer context lines are acceptable as per standard unified diff practice.

### Specific Cases:
*   **Newly Created Files:**
    ```diff
    diff --git a/relative/path/to/new_file.ext b/relative/path/to/new_file.ext
    new file mode 100644
    index 0000000..abcdef0
    --- /dev/null
    +++ b/relative/path/to/new_file.ext
    @@ -0,0 +1,LINES_IN_NEW_FILE @@
    +line 1 of new file
    +line 2 of new file
    ...
    ```
    *(The `new file mode` and `index` lines should be included. Use `100644` for regular files. For the hash in the `index` line, a placeholder like `abcdef0` is acceptable if the actual hash cannot be computed.)*

*   **Deleted Files:**
    ```diff
    diff --git a/relative/path/to/deleted_file.ext b/relative/path/to/deleted_file.ext
    deleted file mode 100644
    index abcdef0..0000000
    --- a/relative/path/to/deleted_file.ext
    +++ /dev/null
    @@ -1,LINES_IN_OLD_FILE +0,0 @@
    -line 1 of old file
    -line 2 of old file
    ...
    ```
    *(The `deleted file mode` and `index` lines should be included. Use a placeholder like `100644` for mode and `abcdef0` for hash if actual values are unknown.)*

*   **Untouched Files:** Do NOT include any diff output for files that have no changes.

### General Constraints on Generated Code:
*   **Minimal & Precise Changes:** Generate the smallest, most targeted diff that correctly implements the `User Task` per all rules.
*   **Preserve Integrity:** Do not break existing functionality unless the `User Task` explicitly requires it. The codebase should remain buildable/runnable.
*   **Leverage Existing Code:** Prefer modifying existing files over creating new ones, unless a new file is architecturally justified or required by `User Task` or `User Rules`.

---"""

# Markdown plan output format constraints for architect mode
OUTPUT_FORMAT_CONSTRAINTS_ARCHITECT = """## 4. Output Format & Constraints (MANDATORY & STRICT)

Your **ONLY** output will be a single, well-structured Markdown document. No other text, explanations, or apologies are permitted outside this Markdown document.

### Markdown Structure (Suggested Outline - Adapt as needed for clarity, maintaining the spirit of each section):

```markdown
# Refactoring/Design Plan: [Brief Title Reflecting User Task]

## 1. Executive Summary & Goals
   - Briefly state the primary objective of this plan.
   - List 2-3 key goals or outcomes.

## 2. Current Situation Analysis (if applicable, especially for refactoring or when `File Structure` is provided)
   - Brief overview of the existing system/component based on `File Structure` or `User Task`.
   - Identify key pain points, limitations, or areas for improvement relevant to the task.

## 3. Proposed Solution / Refactoring Strategy
   ### 3.1. High-Level Design / Architectural Overview
      - Describe the target architecture or the overall approach to refactoring.
      - Use diagrams if they can be represented textually (e.g., Mermaid.js syntax within a code block, or ASCII art). **If a diagram is complex, consider breaking it down into multiple simpler diagrams illustrating different views or components.** Describe them clearly.
   ### 3.2. Key Components / Modules
      - Identify new components to be created or existing ones to be significantly modified.
      - Describe their responsibilities and interactions.
   ### 3.3. Detailed Action Plan / Phases
      - **Phase 1: [Name of Phase]**
         - Objective(s) for this phase.
         - **Priority:** [e.g., High/Medium/Low for the phase itself, if multiple phases can be parallelized or reordered]
         - Task 1.1: [Description]
            - **Rationale/Goal:** [Brief explanation of why this task is needed]
            - **Estimated Effort (Optional):** [e.g., S/M/L, or placeholder for team estimation]
            - **Deliverable/Criteria for Completion:** [What indicates this task is done]
         - Task 1.2: [Description]
            - **Rationale/Goal:** ...
            - **Estimated Effort (Optional):** ...
            - **Deliverable/Criteria for Completion:** ...
         - ...
      - **Phase 2: [Name of Phase] (if applicable)**
         - Objective(s) for this phase.
         - **Priority:** ...
         - Task 2.1: [Description]
            - **Rationale/Goal:** ...
            - **Estimated Effort (Optional):** ...
            - **Deliverable/Criteria for Completion:** ...
         - ...
      - *(Add more phases/tasks as necessary. Tasks should be actionable and logically sequenced. Ensure clear dependencies between tasks are noted either here or in section 4.2.)*
   ### 3.4. Data Model Changes (if applicable)
      - Describe any necessary changes to data structures, database schemas, etc.
   ### 3.5. API Design / Interface Changes (if applicable)
      - Detail new or modified APIs (endpoints, function signatures, data contracts, etc.).
      - Consider versioning, backward compatibility, and potential impact on consumers if relevant.

## 4. Key Considerations & Risk Mitigation
   ### 4.1. Technical Risks & Challenges
      - List potential technical hurdles (e.g., complex migrations, performance bottlenecks, integration with legacy systems).
      - Suggest mitigation strategies or contingency plans.
   ### 4.2. Dependencies
      - List internal (task-to-task, phase-to-phase) and external dependencies (e.g., other teams, third-party services, specific skill availability).
   ### 4.3. Non-Functional Requirements (NFRs) Addressed
      - How the plan addresses key NFRs (scalability, security, performance, maintainability, reliability, usability, etc.). **Be specific about how design choices contribute to these NFRs.**

## 5. Success Metrics / Validation Criteria
   - How will the success of this plan's implementation be measured?
   - What are the key indicators (quantitative or qualitative) that the goals have been achieved?

## 6. Assumptions Made
   - List any assumptions made during the planning process (e.g., about existing infrastructure, team skills, third-party component behavior).

## 7. Open Questions / Areas for Further Investigation
   - List any questions that need answering or areas requiring more detailed research before or during implementation.
   - **(Optional) Key discussion points for the team before finalizing or starting implementation.**

```

### General Constraints on the Plan:
*   **Comprehensive & Detailed:** The plan should provide enough detail for a development team to understand the scope, approach, and individual steps.
*   **Realistic & Achievable:** The proposed plan should be grounded in reality and consider practical implementation constraints.
*   **Forward-Looking:** While addressing the current task, consider future maintainability, scalability, and extensibility where appropriate.
*   **Strictly Markdown:** The entire output must be a single Markdown document. Do not include any preamble or closing remarks outside the Markdown content itself.

---"""

# Markdown analysis report output format constraints for bug mode
OUTPUT_FORMAT_CONSTRAINTS_BUG = """## 4. Output Format & Constraints (MANDATORY & STRICT)

Your **ONLY** output will be a single, well-structured Markdown document. No other text, explanations, or apologies are permitted outside this Markdown document.

### Markdown Structure (Suggested Outline - Adapt as needed for clarity, maintaining the spirit of each section):

```markdown
# Bug Analysis Report: [Brief Bug Title from User Task]

## 1. Executive Summary
   - Brief description of the analyzed bug.
   - Most likely root cause(s) (if identifiable at this stage).
   - Key code areas/modules involved in the problem.

## 2. Bug Description and Context (from `User Task`)
   - **Observed Behavior:** [What is happening]
   - **Expected Behavior:** [What should be happening]
   - **Steps to Reproduce (STR):** [How to reproduce, according to the user]
   - **Environment (if provided):** [Software versions, OS, browser, etc.]
   - **Error Messages (if any):** [Error text]

## 3. Code Execution Path Analysis
   ### 3.1. Entry Point(s) and Initial State
      - Where does the relevant code execution begin (e.g., API controller, UI event handler, cron job start)?
      - What is the assumed initial state of data/system before executing STR?
   ### 3.2. Key Functions/Modules/Components in the Execution Path
      - List and brief description of the role of main code sections (functions, classes, services) through which execution passes.
      - Description of their presumed responsibilities in the context of the task.
   ### 3.3. Execution Flow Tracing
      - **Step 1:** [User Action / System Event] -> `moduleA.functionX()`
         - **Input Data/State:** [What is passed to `functionX` or what is the state of `moduleA`]
         - **Expected behavior of `functionX`:** [What the function should do]
         - **Observed/Presumed Result:** [What actually happens or what might have gone wrong]
      - **Step 2:** `moduleA.functionX()` calls `moduleB.serviceY()`
         - **Input Data/State:** ...
         - **Expected behavior of `serviceY`:** ...
         - **Observed/Presumed Result:** ...
      - **Step N:** [Final Action / Bug Manifestation Point]
         - **Input Data/State:** ...
         - **Expected Behavior:** ...
         - **Observed/Presumed Result:** [How this leads to the observed bug]
      *(Detail the steps, including conditional branches, loops, error handling. Mermaid.js can be used for sequence diagrams or flowcharts if it improves understanding.)*
   ### 3.4. Data State and Flow Analysis
      - How key variables or data structures change (or should change) along the execution path.
      - Where the data flow might deviate from expected, be lost, or corrupted.

## 4. Potential Root Causes and Hypotheses
   ### 4.1. Hypothesis 1: [Brief description of hypothesis, e.g., "Incorrect input data validation"]
      - **Rationale/Evidence:** Why this is a likely cause, based on execution path analysis and code structure. Which code sections support this hypothesis?
      - **Code (if relevant):** Provide code snippets from `File Structure` that might contain the error or point to it.
      - **How it leads to the bug:** Explain the mechanism by which this cause leads to the observed behavior.
   ### 4.2. Hypothesis 2: [E.g., "Error in SQL update query"]
      - **Rationale/Evidence:** ...
      - **Code (if relevant):** ...
      - **How it leads to the bug:** ...
   *(Add as many hypotheses as necessary. Assess their likelihood.)*
   ### 4.3. Most Likely Cause(s)
      - Justify why certain hypotheses are considered most likely.

## 5. Supporting Evidence from Code (if `File Structure` is provided)
   - Direct references to lines/functions in `File Structure` that confirm the analysis or indicate problematic areas.
   - Identification of incorrect logic, missing checks, or wrong assumptions in the code.

## 6. Recommended Steps for Debugging and Verification
   - **Logging:** Which variables and at what code points should be logged to confirm data flow and state?
   - **Breakpoints:** Where is it recommended to set breakpoints and which variables/expressions to inspect?
   - **Test Scenarios/Requests:** What specific input data or scenarios can help isolate the problem?
   - **Clarifying Questions (for user/team):** What additional details might clarify the situation?

## 7. Bug Impact Assessment
   - Brief description of potential consequences if the bug is not fixed (e.g., data loss, incorrect reports, inability to use key functionality, security breach).

## 8. Assumptions Made During Analysis
   - List any assumptions made during the analysis (e.g., about user input, environment configuration, behavior of third-party libraries, missing information).

## 9. Open Questions / Areas for Further Investigation
   - Areas where additional information is needed for a definitive diagnosis.
   - Aspects of the code or system that remain unclear and require further study.
   - **(Optional) Key points for discussion with the team before starting the fix.**

```

### General Constraints on the Report:
*   **Comprehensive & Detailed:** The report must provide enough detail for the development team to understand the analysis process, possible causes, and suggested verification steps.
*   **Logical & Structured:** The analysis must be presented sequentially and logically.
*   **Objective:** Strive for objectivity, basing conclusions on facts and logic.
*   **Strictly Markdown:** The entire output must be a single Markdown document. Do not include any preambles or concluding remarks outside the Markdown document itself.

---"""

PROMPT_TEMPLATES = {
    'dev': """## ROLE & PRIMARY GOAL:
You are a "Robotic Senior Software Engineer AI". Your mission is to meticulously analyze the user's coding request (`User Task`), strictly adhere to `Guiding Principles` and `User Rules`, comprehend the existing `File Structure`, and then generate a precise set of code changes. Your *sole and exclusive output* must be a single `git diff` formatted text. Zero tolerance for any deviation from the specified output format.

---

## INPUT SECTIONS OVERVIEW:
1.  `User Task`: The user's coding problem or feature request.
2.  `Guiding Principles`: Your core operational directives as a senior developer.
3.  `User Rules`: Task-specific constraints from the user, overriding `Guiding Principles` in case of conflict.
4.  `Output Format & Constraints`: Strict rules for your *only* output: the `git diff` text.
5.  `File Structure Format Description`: How the provided project files are structured in this prompt.
6.  `File Structure`: The current state of the project's files.

---

## 1. User Task
{TASK}

---

## 2. Guiding Principles (Your Senior Developer Logic)

### A. Analysis & Planning (Internal Thought Process - Do NOT output this part):
1.  **Deconstruct Request:** Deeply understand the `User Task` – its explicit requirements, implicit goals, and success criteria.
2.  **Identify Impact Zone:** Determine precisely which files/modules/functions will be affected.
3.  **Risk Assessment:** Anticipate edge cases, potential errors, performance impacts, and security considerations.
4.  **Assume with Reason:** If ambiguities exist in `User Task`, make well-founded assumptions based on best practices and existing code context. Document these assumptions internally if complex.
5.  **Optimal Solution Path:** Briefly evaluate alternative solutions, selecting the one that best balances simplicity, maintainability, readability, and consistency with existing project patterns.
6.  **Plan Changes:** Before generating diffs, mentally (or internally) outline the specific changes needed for each affected file.

### B. Code Generation & Standards:
*   **Simplicity & Idiomatic Code:** Prioritize the simplest, most direct solution. Write code that is idiomatic for the language and aligns with project conventions (inferred from `File Structure`). Avoid over-engineering.
*   **Respect Existing Architecture:** Strictly follow the established project structure, naming conventions, and coding style.
*   **Type Safety:** Employ type hints/annotations as appropriate for the language.
*   **Modularity:** Design changes to be modular and reusable where sensible.
*   **Documentation:**
    *   Add concise docstrings/comments for new public APIs, complex logic, or non-obvious decisions.
    *   Update existing documentation if changes render it inaccurate.
*   **Logging:** Introduce logging for critical operations or error states if consistent with the project's logging strategy.
*   **No New Dependencies:** Do NOT introduce external libraries/dependencies unless explicitly stated in `User Task` or `User Rules`.
*   **Atomicity of Changes (Hunks):** Each distinct change block (hunk in the diff output) should represent a small, logically coherent modification.
*   **Testability:** Design changes to be testable. If a testing framework is evident in `File Structure` or mentioned in `User Rules`, ensure new code is compatible.

---

## 3. User Rules
{RULES}
*(These are user-provided, project-specific rules or task constraints. They take precedence over `Guiding Principles`.)*

---

{OUTPUT_FORMAT_CONSTRAINTS}

## 5. File Structure Format Description
The `File Structure` (provided in the next section) is formatted as follows:
1.  An initial project directory tree structure (e.g., generated by `tree` or similar).
2.  Followed by the content of each file, using an XML-like structure:
    <file path="RELATIVE/PATH/TO/FILE">
    (File content here)
    </file>
    The `path` attribute contains the project-root-relative path, using forward slashes (`/`).
    File content is the raw text of the file. Each file block is separated by a newline.

---

## 6. File Structure
{PROJECT_TREE}

{FILE_STRUCTURE}""",

    'architect': """## ROLE & PRIMARY GOAL:
You are a "Robotic Senior System Architect AI". Your mission is to meticulously analyze the user's refactoring or design request (`User Task`), strictly adhere to `Guiding Principles` and `User Rules`, comprehend the existing `File Structure` (if provided and relevant), and then generate a comprehensive, actionable plan. Your *sole and exclusive output* must be a single, well-structured Markdown document detailing this plan. Zero tolerance for any deviation from the specified output format.

---

## INPUT SECTIONS OVERVIEW:
1.  `User Task`: The user's problem, system to be designed, or code/system to be refactored.
2.  `Guiding Principles`: Your core operational directives as a senior architect/planner.
3.  `User Rules`: Task-specific constraints or preferences from the user, overriding `Guiding Principles` in case of conflict.
4.  `Output Format & Constraints`: Strict rules for your *only* output: the Markdown plan.
5.  `File Structure Format Description`: How the provided project files are structured in this prompt (if applicable).
6.  `File Structure`: The current state of the project's files (if applicable to the task).

---

## 1. User Task
{TASK}

---

## 2. Guiding Principles (Your Senior Architect/Planner Logic)

### A. Analysis & Understanding (Internal Thought Process - Do NOT output this part):
1.  **Deconstruct Request:** Deeply understand the `User Task` – its explicit requirements, implicit goals, underlying problems, and success criteria.
2.  **Contextual Comprehension:** If `File Structure` is provided, analyze it to understand the current system's architecture, components, dependencies, and potential pain points relevant to the task.
3.  **Scope Definition:** Clearly delineate the boundaries of the proposed plan. What is in scope and what is out of scope?
4.  **Identify Key Areas:** Determine the primary systems, modules, components, or processes that the plan will address.
5.  **Risk Assessment & Mitigation:** Anticipate potential challenges, technical debt, integration issues, performance impacts, scalability concerns, and security considerations. Propose mitigation strategies or areas needing further investigation.
6.  **Assumptions:** If ambiguities exist in `User Task` or `File Structure`, make well-founded assumptions based on best practices, common architectural patterns, and the provided context. Document these assumptions clearly in the output.
7.  **Evaluate Alternatives (Briefly):** Internally consider different approaches or high-level solutions, selecting or recommending the one that best balances requirements, constraints, maintainability, scalability, and long-term vision.

### B. Plan Generation & Standards:
*   **Clarity & Actionability:** The plan must be clear, concise, and broken down into actionable steps or phases. Each step should have a discernible purpose **and, where appropriate, suggest criteria for its completion (Definition of Done) or potential for high-level effort estimation (e.g., S/M/L).**
*   **Justification:** Provide rationale for key decisions, architectural choices, or significant refactoring steps. Explain the "why" behind the "what."
*   **Modularity & Cohesion:** Design plans that promote modularity, separation of concerns, and high cohesion within components.
*   **Scalability & Performance:** Consider how the proposed design or refactoring will impact system scalability and performance.
*   **Maintainability & Testability:** The resulting system (after implementing the plan) should be maintainable and testable. The plan might include suggestions for improving these aspects.
*   **Phased Approach:** For complex tasks, break down the plan into logical phases or milestones. Define clear objectives for each phase. **Consider task prioritization within and between phases.**
*   **Impact Analysis:** Describe the potential impact of the proposed changes on existing functionality, users, or other systems.
*   **Dependencies:** Identify key dependencies between tasks within the plan or dependencies on external factors/teams.
*   **Non-Functional Requirements (NFRs):** Explicitly address any NFRs mentioned in the `User Task` or inferable as critical (e.g., security, reliability, usability, performance). **Security aspects should be considered by design.**
*   **Technology Choices (if applicable):** If new technologies are proposed, justify their selection, **briefly noting potential integration challenges or learning curves.** If existing technologies are leveraged, ensure the plan aligns with their best practices.
*   **No Implementation Code:** The output is a plan, not code. Pseudocode or illustrative snippets are acceptable *within the plan document* if they clarify a complex point, but full code implementation is out of scope for this role.

---

## 3. User Rules
{RULES}
*(These are user-provided, project-specific rules, methodological preferences (e.g., "Prioritize DDD principles"), or task constraints. They take precedence over `Guiding Principles`.)*

---

{OUTPUT_FORMAT_CONSTRAINTS}

## 5. File Structure Format Description
The `File Structure` (provided in the next section, if applicable) is formatted as follows:
1.  An initial project directory tree structure (e.g., generated by `tree` or similar).
2.  Followed by the content of each file, using an XML-like structure:
    <file path="RELATIVE/PATH/TO/FILE">
    (File content here)
    </file>
    The `path` attribute contains the project-root-relative path, using forward slashes (`/`).
    File content is the raw text of the file. Each file block is separated by a newline.
    *(This section may be omitted if no file structure is relevant to the task).*

---

## 6. File Structure
{PROJECT_TREE}

{FILE_STRUCTURE}""",

    'bug': """## ROLE & PRIMARY GOAL:
You are a "Robotic Senior Debugging Analyst AI". Your mission is to meticulously trace code execution paths based on the user's bug description (`User Task`), identify potential root causes, strictly adhere to `Guiding Principles` and `User Rules`, comprehend the existing `File Structure` (if provided and relevant), and then generate a comprehensive, detailed **Bug Analysis Report**. Your *sole and exclusive output* must be a single, well-structured Markdown document detailing this analysis. Zero tolerance for any deviation from the specified output format.

---

## INPUT SECTIONS OVERVIEW:
1.  `User Task`: The user's description of the bug, observed behavior, expected behavior, and steps to reproduce.
2.  `Guiding Principles`: Your core operational directives as a senior debugging analyst.
3.  `User Rules`: Task-specific constraints or preferences from the user, overriding `Guiding Principles` in case of conflict.
4.  `Output Format & Constraints`: Strict rules for your *only* output: the Markdown Bug Analysis Report.
5.  `File Structure Format Description`: How the provided project files are structured in this prompt (if applicable).
6.  `File Structure`: The current state of the project's files (if applicable to the task).

---

## 1. User Task
{TASK}
*(Example: "When clicking the 'Save' button on the profile page, user data is not updated in the database, although the interface shows a success message. It is expected that the data will be saved. Steps: 1. Log in. 2. Go to profile. 3. Change name. 4. Click 'Save'. 5. Refresh page - name is old.")*

---

## 2. Guiding Principles (Your Senior Debugging Analyst Logic)

### A. Analysis & Understanding (Internal Thought Process - Do NOT output this part):
1.  **Deconstruct Bug Report:** Deeply understand the `User Task` – observed behavior, expected behavior, steps to reproduce (STR), environment details (if provided), and any error messages.
2.  **Contextual Comprehension:** If `File Structure` is provided, analyze it to understand the relevant code modules, functions, data flow, dependencies, and potential areas related to the bug.
3.  **Hypothesis Generation:** Formulate initial hypotheses about potential causes based on the bug description, STR, and code structure. Consider common bug categories (e.g., logic errors, race conditions, data validation issues, environment misconfigurations, third-party integration problems).
4.  **Execution Path Mapping (Mental or Simulated):** Meticulously trace the likely execution path(s) of the code involved in reproducing the bug. Consider:
    *   Entry points for the user action.
    *   Function calls, method invocations, and their sequence.
    *   Conditional branches (if/else, switch statements).
    *   Loops and their termination conditions.
    *   Asynchronous operations, callbacks, promises, event handling.
    *   Data transformations and state changes at each step.
    *   Error handling mechanisms (try/catch blocks, error events).
5.  **Identify Key Checkpoints & Variables:** Determine critical points in the code execution or specific variables whose state (or changes in state) could confirm or refute hypotheses and reveal the bug's origin.
6.  **Information Gap Analysis:** Identify what information is missing that would help confirm/refute hypotheses (e.g., specific log messages, variable values at certain points, network request/response details).
7.  **Assumptions:** If ambiguities exist in `User Task` or `File Structure`, make well-founded assumptions based on common programming practices, the described system behavior, and the provided context. Document these assumptions clearly in the output.
8.  **Consider Edge Cases & Interactions:** Think about how different components interact, potential concurrency issues, error propagation, and edge cases related to input data or system state that might trigger the bug.

### B. Report Generation & Standards:
*   **Clarity & Detail:** The report must clearly explain the analysis process, the traced execution path(s), and the reasoning behind identified potential causes. Use precise language.
*   **Evidence-Based Reasoning:** Base conclusions on the provided `User Task`, `File Structure` (if available), and logical deduction. If speculation is necessary, clearly label it as such and state the confidence level.
*   **Focus on Root Cause(s):** Aim to identify the underlying root cause(s) of the bug, not just its symptoms. Distinguish between correlation and causation.
*   **Actionable Insights for Debugging:** Suggest specific areas of code to inspect further, logging to add (and what data to log), breakpoints to set, or specific tests/scenarios to run to confirm the diagnosis.
*   **Reproducibility Analysis:** Based on the execution path tracing, confirm if the user's STR are logical and sufficient, or suggest refinements if the analysis reveals missing steps or conditions.
*   **Impact Assessment (of the bug):** Briefly describe the potential impact of the bug if not fixed, based on the analysis.
*   **No Code Fixes:** The output is an analysis report, not fixed code. Code snippets illustrating the problematic execution flow, data state, or specific lines of code relevant to the bug are highly encouraged *within the report document* to clarify points.

---

## 3. User Rules
{RULES}
*(Example: "Assume PostgreSQL is used as the DB.", "Focus on backend logic.", "Do not consider UI problems unless they indicate an error in data coming from the backend.")*

---

{OUTPUT_FORMAT_CONSTRAINTS}

## 5. File Structure Format Description
The `File Structure` (provided in the next section, if applicable) is formatted as follows:
1.  An initial project directory tree structure (e.g., generated by `tree` or similar).
2.  Followed by the content of each file, using an XML-like structure:
    <file path="RELATIVE/PATH/TO/FILE">
    (File content here)
    </file>
    The `path` attribute contains the project-root-relative path, using forward slashes (`/`).
    File content is the raw text of the file. Each file block is separated by a newline.
    *(This section may be omitted if no file structure is relevant to the task).*

---

## 6. File Structure
{PROJECT_TREE}

{FILE_STRUCTURE}"""
}

def process_template(template_type: str, task: str, rules: str, file_structure: str, project_tree: str = "") -> str:
    """Process template with placeholder replacement."""
    template = PROMPT_TEMPLATES.get(template_type, PROMPT_TEMPLATES['dev'])
    
    # Select appropriate output format constraints based on template type
    if template_type == 'architect':
        output_constraints = OUTPUT_FORMAT_CONSTRAINTS_ARCHITECT
    elif template_type == 'bug':
        output_constraints = OUTPUT_FORMAT_CONSTRAINTS_BUG
    else:  # dev mode
        output_constraints = OUTPUT_FORMAT_CONSTRAINTS_DEV
    
    # Replace placeholders
    processed = template.replace('{TASK}', task.strip())
    processed = processed.replace('{RULES}', rules.strip())
    processed = processed.replace('{FILE_STRUCTURE}', file_structure.strip())
    processed = processed.replace('{PROJECT_TREE}', project_tree.strip())
    processed = processed.replace('{OUTPUT_FORMAT_CONSTRAINTS}', output_constraints)
    processed = processed.replace('{CURRENT_DATE}', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    
    return processed
</file>
<file path="shotgun_terminal/settings.py">
"""Settings management with XDG-compliant storage."""

import json
import os
from pathlib import Path
from typing import Dict, Any

class SettingsManager:
    """Manage application settings with XDG-compliant storage."""
    
    def __init__(self):
        self.config_dir = self._get_config_dir()
        self.settings_file = self.config_dir / "settings.json"
        self.ensure_config_dir()
    
    def _get_config_dir(self) -> Path:
        """Get XDG-compliant config directory."""
        # Use XDG_CONFIG_HOME if set, otherwise default to ~/.config
        config_home = os.environ.get('XDG_CONFIG_HOME')
        if config_home:
            return Path(config_home) / "shotgun-code"
        else:
            return Path.home() / ".config" / "shotgun-code"
    
    def ensure_config_dir(self):
        """Ensure config directory exists."""
        self.config_dir.mkdir(parents=True, exist_ok=True)
    
    def load_settings(self) -> Dict[str, Any]:
        """Load settings from file."""
        if not self.settings_file.exists():
            return self._get_default_settings()
        
        try:
            with open(self.settings_file, 'r', encoding='utf-8') as f:
                settings = json.load(f)
            
            # Merge with defaults to ensure all keys exist
            default_settings = self._get_default_settings()
            default_settings.update(settings)
            return default_settings
            
        except (json.JSONDecodeError, IOError):
            return self._get_default_settings()
    
    def save_settings(self, settings: Dict[str, Any]):
        """Save settings to file."""
        try:
            with open(self.settings_file, 'w', encoding='utf-8') as f:
                json.dump(settings, f, indent=2, ensure_ascii=False)
        except IOError as e:
            raise Exception(f"Failed to save settings: {e}")
    
    def _get_default_settings(self) -> Dict[str, Any]:
        """Get default settings."""
        return {
            "customIgnoreRules": "\n".join([
                "*.pyc",
                "__pycache__",
                ".git",
                ".gitignore", 
                "*.log",
                "node_modules",
                ".env",
                "*.tmp",
                ".DS_Store",
                "build",
                "dist",
                "*.egg-info",
                ".vscode",
                ".idea"
            ]),
            "customPromptRules": "\n".join([
                "- Follow the existing code style and conventions",
                "- Write clear, readable, and maintainable code",
                "- Add appropriate comments and documentation",
                "- Handle errors gracefully", 
                "- Use meaningful variable and function names",
                "- Follow security best practices",
                "- Optimize for performance when appropriate"
            ]),
            "lastUsedDirectory": "",
            "defaultPromptType": "dev",
            "recentTasks": [],
            "apiSettings": {
                "api_key": "",
                "base_url": "",
                "model": "gpt-4.1",
                "enable_translation": True
            }
        }
    
    def get_custom_ignore_rules(self) -> str:
        """Get custom ignore rules."""
        settings = self.load_settings()
        return settings.get("customIgnoreRules", "")
    
    def set_custom_ignore_rules(self, rules: str):
        """Set custom ignore rules."""
        settings = self.load_settings()
        settings["customIgnoreRules"] = rules
        self.save_settings(settings)
    
    def get_custom_prompt_rules(self) -> str:
        """Get custom prompt rules."""
        settings = self.load_settings()
        return settings.get("customPromptRules", "")
    
    def set_custom_prompt_rules(self, rules: str):
        """Set custom prompt rules."""
        settings = self.load_settings()
        settings["customPromptRules"] = rules
        self.save_settings(settings)
    
    def get_recent_tasks(self) -> list:
        """Get recent tasks."""
        settings = self.load_settings()
        return settings.get("recentTasks", [])
    
    def add_recent_task(self, task: str):
        """Add task to recent tasks (keep last 10)."""
        settings = self.load_settings()
        recent_tasks = settings.get("recentTasks", [])
        
        # Remove if already exists
        if task in recent_tasks:
            recent_tasks.remove(task)
        
        # Add to beginning
        recent_tasks.insert(0, task)
        
        # Keep only last 10
        recent_tasks = recent_tasks[:10]
        
        settings["recentTasks"] = recent_tasks
        self.save_settings(settings)
    
    def get_last_used_directory(self) -> str:
        """Get last used directory."""
        settings = self.load_settings()
        return settings.get("lastUsedDirectory", "")
    
    def set_last_used_directory(self, directory: str):
        """Set last used directory."""
        settings = self.load_settings()
        settings["lastUsedDirectory"] = directory
        self.save_settings(settings)
    
    def get_api_settings(self) -> Dict[str, Any]:
        """Get API settings."""
        settings = self.load_settings()
        return settings.get("apiSettings", {
            "api_key": "",
            "base_url": "",
            "model": "gpt-4.1",
            "enable_translation": True
        })
    
    def set_api_settings(self, api_key: str, base_url: str, model: str = "gpt-4.1", enable_translation: bool = True):
        """Set API settings."""
        settings = self.load_settings()
        settings["apiSettings"] = {
            "api_key": api_key,
            "base_url": base_url,
            "model": model,
            "enable_translation": enable_translation
        }
        self.save_settings(settings)
    
    def is_translation_enabled(self) -> bool:
        """Check if translation is enabled."""
        api_settings = self.get_api_settings()
        return api_settings.get("enable_translation", True)
    
    def set_translation_enabled(self, enabled: bool):
        """Enable or disable translation."""
        settings = self.load_settings()
        if "apiSettings" not in settings:
            settings["apiSettings"] = self._get_default_settings()["apiSettings"]
        settings["apiSettings"]["enable_translation"] = enabled
        self.save_settings(settings)
</file>
<file path="shotgun_terminal/translator.py">
"""Translation service using OpenAI-compatible API."""

import openai
from typing import Optional
from rich.console import Console

from .settings import SettingsManager

console = Console()

class TranslationService:
    """Handle translation using OpenAI-compatible API."""
    
    def __init__(self):
        self.settings = SettingsManager()
        self.client = None
        self._initialize_client()
    
    def _initialize_client(self):
        """Initialize OpenAI client with saved settings."""
        api_settings = self.settings.get_api_settings()
        
        if api_settings.get('api_key') and api_settings.get('base_url'):
            try:
                self.client = openai.OpenAI(
                    api_key=api_settings['api_key'],
                    base_url=api_settings['base_url']
                )
            except Exception as e:
                console.print(f"[yellow]Warning: Failed to initialize API client: {e}[/yellow]")
                self.client = None
    
    def is_configured(self) -> bool:
        """Check if API is properly configured."""
        return self.client is not None
    
    def translate_to_english(self, text: str, text_type: str = "text") -> Optional[str]:
        """
        Translate text to English using the configured API.
        
        Args:
            text: Text to translate
            text_type: Type of text ("task" or "rules" for context)
            
        Returns:
            Translated text or None if translation fails
        """
        if not self.is_configured():
            console.print("[yellow]API not configured. Use 'shotgun-terminal --config' to set up translation.[/yellow]")
            return None
        
        if not text.strip():
            return text
        
        # Check if text is already in English (simple heuristic)
        if self._is_likely_english(text):
            console.print(f"[blue]Text appears to be in English already, skipping translation[/blue]")
            return text
        
        try:
            # Get model from settings
            api_settings = self.settings.get_api_settings()
            model = api_settings.get('model', 'gpt-4.1')
            
            # Create appropriate prompt based on text type
            if text_type == "task":
                system_prompt = """You are a professional translator. Translate the following task description to English. 
Keep the meaning precise and technical terms accurate. Return only the translated text without any additional commentary."""
            elif text_type == "rules":
                system_prompt = """You are a professional translator. Translate the following coding rules/guidelines to English. 
Keep technical terms accurate and maintain the list format. Return only the translated text without any additional commentary."""
            else:
                system_prompt = """You are a professional translator. Translate the following text to English. 
Return only the translated text without any additional commentary."""
            
            console.print(f"[blue]Translating {text_type} to English...[/blue]")
            
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                temperature=0.1,  # Low temperature for consistent translation
                max_tokens=2000
            )
            
            translated_text = response.choices[0].message.content.strip()
            console.print(f"[green]✓[/green] Translation completed")
            
            return translated_text
            
        except Exception as e:
            console.print(f"[red]Translation failed:[/red] {e}")
            console.print(f"[yellow]Using original text in Portuguese[/yellow]")
            return None
    
    def _is_likely_english(self, text: str) -> bool:
        """
        Simple heuristic to check if text is likely already in English.
        
        This is a basic check - looks for common Portuguese words/patterns.
        """
        portuguese_indicators = [
            'ção', 'ções', 'ão', 'ões', 'nh', 'lh', 
            'que', 'para', 'com', 'uma', 'não', 'são', 'está', 'foi',
            'fazer', 'implementar', 'criar', 'adicionar', 'corrigir',
            'função', 'método', 'classe', 'arquivo', 'código'
        ]
        
        text_lower = text.lower()
        portuguese_count = sum(1 for indicator in portuguese_indicators if indicator in text_lower)
        
        # If we find multiple Portuguese indicators, assume it's Portuguese
        return portuguese_count < 2
    
    def test_connection(self) -> bool:
        """Test API connection and configuration."""
        if not self.is_configured():
            return False
        
        try:
            console.print("[blue]Testing API connection...[/blue]")
            
            # Get model from settings
            api_settings = self.settings.get_api_settings()
            model = api_settings.get('model', 'gpt-4.1')
            
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "user", "content": "Hello, this is a test. Please respond with 'Test successful'."}
                ],
                max_tokens=10
            )
            
            result = response.choices[0].message.content.strip()
            console.print(f"[green]✓[/green] API test successful: {result}")
            return True
            
        except Exception as e:
            console.print(f"[red]API test failed:[/red] {e}")
            return False
</file>
<file path="shotgun_terminal/tree_generator.py">
"""Generate file tree structure similar to the tree command."""

import os
from pathlib import Path
from typing import List, Set

class TreeGenerator:
    """Generate a tree structure representation of the project directory."""
    
    def __init__(self, directory: str):
        self.directory = Path(directory)
        self.tree_chars = {
            'branch': '├── ',
            'last': '└── ',
            'extension': '│   ',
            'space': '    '
        }
    
    def generate_tree(self, included_files: List[str], ignore_patterns: List[str] = None) -> str:
        """
        Generate a tree structure for the given files.
        
        Args:
            included_files: List of relative file paths to include
            ignore_patterns: List of patterns to ignore (unused here, files already filtered)
            
        Returns:
            Tree structure as string
        """
        if not included_files:
            return ""
        
        # Build directory structure from included files
        tree_structure = {}
        
        for file_path in included_files:
            parts = Path(file_path).parts
            current = tree_structure
            
            # Build nested structure
            for i, part in enumerate(parts):
                if part not in current:
                    current[part] = {}
                current = current[part]
        
        # Generate tree string
        project_name = self.directory.name
        lines = [f"{project_name}\\"]
        
        self._build_tree_lines(tree_structure, lines, "", True)
        
        return '\n'.join(lines)
    
    def _build_tree_lines(self, structure: dict, lines: list, prefix: str, is_root: bool = False):
        """Recursively build tree lines."""
        items = sorted(structure.keys())
        
        for i, item in enumerate(items):
            is_last = (i == len(items) - 1)
            
            # Determine prefix for this item
            if is_root:
                current_prefix = self.tree_chars['last'] if is_last else self.tree_chars['branch']
            else:
                current_prefix = prefix + (self.tree_chars['last'] if is_last else self.tree_chars['branch'])
            
            lines.append(current_prefix + item)
            
            # If this item has children (is a directory), recurse
            if structure[item]:
                # Determine prefix for children
                if is_root:
                    child_prefix = self.tree_chars['space'] if is_last else self.tree_chars['extension']
                else:
                    child_prefix = prefix + (self.tree_chars['space'] if is_last else self.tree_chars['extension'])
                
                self._build_tree_lines(structure[item], lines, child_prefix)
    
    def generate_full_tree(self, max_depth: int = 3) -> str:
        """
        Generate a full tree of the directory (for reference).
        
        Args:
            max_depth: Maximum depth to traverse
            
        Returns:
            Tree structure as string
        """
        lines = [f"{self.directory.name}\\"]
        
        try:
            self._traverse_directory(self.directory, lines, "", 0, max_depth, True)
        except Exception:
            # Fallback to simple listing if tree generation fails
            lines.append("├── (files)")
        
        return '\n'.join(lines)
    
    def _traverse_directory(self, directory: Path, lines: list, prefix: str, depth: int, max_depth: int, is_root: bool = False):
        """Traverse directory and build tree."""
        if depth > max_depth:
            return
        
        try:
            items = []
            # Get directories and files separately
            for item in directory.iterdir():
                if not item.name.startswith('.'):  # Skip hidden files/dirs
                    items.append(item)
            
            # Sort: directories first, then files
            items.sort(key=lambda x: (x.is_file(), x.name.lower()))
            
            for i, item in enumerate(items):
                is_last = (i == len(items) - 1)
                
                # Determine prefix for this item
                if is_root:
                    current_prefix = self.tree_chars['last'] if is_last else self.tree_chars['branch']
                else:
                    current_prefix = prefix + (self.tree_chars['last'] if is_last else self.tree_chars['branch'])
                
                lines.append(current_prefix + item.name)
                
                # If directory, recurse
                if item.is_dir() and depth < max_depth:
                    if is_root:
                        child_prefix = self.tree_chars['space'] if is_last else self.tree_chars['extension']
                    else:
                        child_prefix = prefix + (self.tree_chars['space'] if is_last else self.tree_chars['extension'])
                    
                    self._traverse_directory(item, lines, child_prefix, depth + 1, max_depth)
        
        except PermissionError:
            # Skip directories we can't access
            pass
</file>
<file path="shotgun_terminal/user_input.py">
"""User input collection module."""

import tempfile
import subprocess
import os
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt, Confirm
import inquirer

from .settings import SettingsManager

console = Console()

class UserInputCollector:
    """Collect user task and custom rules input."""
    
    def __init__(self):
        self.settings = SettingsManager()
    
    def collect_user_task(self) -> str:
        """Collect user task description."""
        console.print(Panel.fit(
            "[bold yellow]📝 Task Description[/bold yellow]\n"
            "Describe what you want to achieve with this project",
            border_style="yellow"
        ))
        
        # Show recent tasks if available
        recent_tasks = self.settings.get_recent_tasks()
        if recent_tasks:
            console.print("\n[blue]Recent tasks:[/blue]")
            for i, task in enumerate(recent_tasks[:5], 1):
                preview = task[:80] + "..." if len(task) > 80 else task
                console.print(f"{i}. {preview}")
            
            use_recent = Confirm.ask("\nUse a recent task?", default=False)
            if use_recent:
                questions = [
                    inquirer.List('task',
                                message="Select recent task",
                                choices=[(f"{task[:80]}..." if len(task) > 80 else task, task) 
                                       for task in recent_tasks[:5]])
                ]
                answer = inquirer.prompt(questions)
                if answer:
                    selected_task = answer['task']
                    console.print(f"\n[green]Selected task:[/green] {selected_task[:100]}...")
                    return selected_task
        
        # Manual task input
        console.print("\n[yellow]Enter your task description:[/yellow]")
        console.print("[dim]You can describe what you want to do, what needs to be fixed, or what feature to implement[/dim]")
        
        # Option for multiline input
        use_editor = Confirm.ask("Use external editor for multiline input?", default=False)
        
        if use_editor:
            task = self._get_multiline_input()
        else:
            task = Prompt.ask("Task description", default="")
        
        if not task.strip():
            console.print("[red]Task description cannot be empty[/red]")
            return self.collect_user_task()
        
        # Save to recent tasks
        self.settings.add_recent_task(task)
        
        return task
    
    def collect_custom_rules(self) -> str:
        """Collect custom prompt rules."""
        console.print(Panel.fit(
            "[bold cyan]⚙️ Custom Rules[/bold cyan]\n"
            "Define specific rules and guidelines for the AI to follow",
            border_style="cyan"
        ))
        
        # Load current rules
        current_rules = self.settings.get_custom_prompt_rules()
        
        console.print("\n[blue]Current custom rules:[/blue]")
        self._show_rules_preview(current_rules)
        
        modify_rules = Confirm.ask("\nModify custom rules?", default=False)
        
        if not modify_rules:
            return current_rules
        
        # Choose modification method
        action = inquirer.list_input(
            "How would you like to modify the rules?",
            choices=[
                'Edit in external editor',
                'Add new rule',
                'Remove rule',
                'Reset to defaults',
                'Keep current'
            ]
        )
        
        if action == 'Edit in external editor':
            new_rules = self._edit_rules_in_editor(current_rules)
            if new_rules != current_rules:
                self.settings.set_custom_prompt_rules(new_rules)
            return new_rules
        
        elif action == 'Add new rule':
            new_rule = Prompt.ask("Enter new rule")
            if new_rule.strip():
                rules_list = current_rules.split('\n') if current_rules else []
                rules_list.append(f"- {new_rule.strip()}")
                new_rules = '\n'.join(rules_list)
                self.settings.set_custom_prompt_rules(new_rules)
                console.print(f"[green]Added rule:[/green] {new_rule}")
                return new_rules
        
        elif action == 'Remove rule':
            if current_rules:
                rules_list = [rule for rule in current_rules.split('\n') if rule.strip()]
                if rules_list:
                    questions = [
                        inquirer.Checkbox('rules',
                                        message="Select rules to remove",
                                        choices=rules_list)
                    ]
                    answers = inquirer.prompt(questions)
                    for rule in answers['rules']:
                        rules_list.remove(rule)
                    new_rules = '\n'.join(rules_list)
                    self.settings.set_custom_prompt_rules(new_rules)
                    console.print(f"[red]Removed {len(answers['rules'])} rules[/red]")
                    return new_rules
            console.print("[yellow]No rules to remove[/yellow]")
        
        elif action == 'Reset to defaults':
            if Confirm.ask("Reset to default rules? This will overwrite your custom rules.", default=False):
                default_settings = self.settings._get_default_settings()
                default_rules = default_settings["customPromptRules"]
                self.settings.set_custom_prompt_rules(default_rules)
                console.print("[green]Reset to default rules[/green]")
                return default_rules
        
        return current_rules
    
    def _show_rules_preview(self, rules: str):
        """Show preview of rules."""
        if not rules:
            console.print("[dim]No custom rules defined[/dim]")
            return
        
        rules_list = rules.split('\n')
        for i, rule in enumerate(rules_list[:5], 1):
            if rule.strip():
                console.print(f"{i}. {rule}")
        
        if len(rules_list) > 5:
            console.print(f"... and {len(rules_list) - 5} more rules")
    
    def _get_multiline_input(self) -> str:
        """Get multiline input using external editor."""
        try:
            # Create temporary file
            with tempfile.NamedTemporaryFile(mode='w+', suffix='.txt', delete=False) as tf:
                tf.write("# Enter your task description here\n")
                tf.write("# Lines starting with # will be ignored\n\n")
                temp_path = tf.name
            
            # Open in editor
            editor = os.environ.get('EDITOR', 'notepad' if os.name == 'nt' else 'nano')
            subprocess.run([editor, temp_path], check=True)
            
            # Read content
            with open(temp_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Clean up
            os.unlink(temp_path)
            
            # Filter out comments
            lines = [line for line in content.split('\n') if not line.strip().startswith('#')]
            return '\n'.join(lines).strip()
            
        except Exception as e:
            console.print(f"[red]Error using editor:[/red] {e}")
            console.print("[yellow]Falling back to simple input[/yellow]")
            return Prompt.ask("Task description")
    
    def _edit_rules_in_editor(self, current_rules: str) -> str:
        """Edit rules in external editor."""
        try:
            # Create temporary file with current rules
            with tempfile.NamedTemporaryFile(mode='w+', suffix='.txt', delete=False) as tf:
                tf.write("# Custom Prompt Rules\n")
                tf.write("# Each line should be a rule (- prefix optional)\n")
                tf.write("# Lines starting with # will be ignored\n\n")
                tf.write(current_rules)
                temp_path = tf.name
            
            # Open in editor
            editor = os.environ.get('EDITOR', 'notepad' if os.name == 'nt' else 'nano')
            subprocess.run([editor, temp_path], check=True)
            
            # Read content
            with open(temp_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Clean up
            os.unlink(temp_path)
            
            # Filter out comments and clean up
            lines = []
            for line in content.split('\n'):
                line = line.strip()
                if line and not line.startswith('#'):
                    if not line.startswith('-'):
                        line = f"- {line}"
                    lines.append(line)
            
            return '\n'.join(lines)
            
        except Exception as e:
            console.print(f"[red]Error using editor:[/red] {e}")
            return current_rules
</file>
<file path="shotgun_terminal.egg-info/dependency_links.txt">


</file>
<file path="shotgun_terminal.egg-info/entry_points.txt">
[console_scripts]
shotgun-terminal = shotgun_terminal.cli:main

</file>
<file path="shotgun_terminal.egg-info/PKG-INFO">
Metadata-Version: 2.4
Name: shotgun-terminal
Version: 0.1.0
Summary: Terminal version of Shotgun - Generate comprehensive project context for LLM workflows
Author: Shotgun Code Team
License: MIT
Project-URL: Homepage, https://github.com/shotgun-code/shotgun-terminal
Project-URL: Repository, https://github.com/shotgun-code/shotgun-terminal
Project-URL: Issues, https://github.com/shotgun-code/shotgun-terminal/issues
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: click>=8.0.0
Requires-Dist: rich>=10.0.0
Requires-Dist: inquirer>=2.8.0
Requires-Dist: openai>=1.0.0
Requires-Dist: requests>=2.25.0
Dynamic: requires-python

# Shotgun Terminal

Terminal version of Shotgun - Generate comprehensive project context for LLM workflows.

## Installation

```bash
pip install shotgun-terminal
```

## Usage

```bash
shotgun-terminal
```

The application will guide you through an interactive process to:

1. Select your project directory
2. Choose files to include/exclude from context
3. Select prompt type (Dev, Architect, Find Bug)
4. Generate context output to a .txt file

## Features

- Interactive file selection
- Multiple prompt types for different use cases
- Customizable ignore patterns
- Rich terminal interface
- Pip-installable package

## Requirements

- Python 3.8+
- files-to-prompt library
- Interactive terminal

</file>
<file path="shotgun_terminal.egg-info/requires.txt">
click>=8.0.0
rich>=10.0.0
inquirer>=2.8.0
openai>=1.0.0
requests>=2.25.0

</file>
<file path="shotgun_terminal.egg-info/SOURCES.txt">
README.md
pyproject.toml
setup.py
shotgun_terminal/__init__.py
shotgun_terminal/cli.py
shotgun_terminal/config.py
shotgun_terminal/context_generator.py
shotgun_terminal/file_selector.py
shotgun_terminal/prompts.py
shotgun_terminal/settings.py
shotgun_terminal/translator.py
shotgun_terminal/tree_generator.py
shotgun_terminal/user_input.py
shotgun_terminal.egg-info/PKG-INFO
shotgun_terminal.egg-info/SOURCES.txt
shotgun_terminal.egg-info/dependency_links.txt
shotgun_terminal.egg-info/entry_points.txt
shotgun_terminal.egg-info/requires.txt
shotgun_terminal.egg-info/top_level.txt
</file>
<file path="shotgun_terminal.egg-info/top_level.txt">
shotgun_terminal

</file>
<file path="pyproject.toml">
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "shotgun-terminal"
version = "0.1.0"
description = "Terminal version of Shotgun - Generate comprehensive project context for LLM workflows"
readme = "README.md"
license = {text = "MIT"}
authors = [
    {name = "Shotgun Code Team"}
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
]
requires-python = ">=3.8"
dependencies = [
    "click>=8.0.0",
    "rich>=10.0.0",
    "inquirer>=2.8.0",
    "openai>=1.0.0",
    "requests>=2.25.0",
]

[project.scripts]
shotgun-terminal = "shotgun_terminal.cli:main"

[project.urls]
Homepage = "https://github.com/shotgun-code/shotgun-terminal"
Repository = "https://github.com/shotgun-code/shotgun-terminal"
Issues = "https://github.com/shotgun-code/shotgun-terminal/issues"
</file>
<file path="README.md">
# Shotgun Terminal

Terminal version of Shotgun - Generate comprehensive project context for LLM workflows.

## Installation

```bash
pip install shotgun-terminal
```

## Usage

```bash
shotgun-terminal
```

The application will guide you through an interactive process to:

1. Select your project directory
2. Choose files to include/exclude from context
3. Select prompt type (Dev, Architect, Find Bug)
4. Generate context output to a .txt file

## Features

- Interactive file selection
- Multiple prompt types for different use cases
- Customizable ignore patterns
- Rich terminal interface
- Pip-installable package

## Requirements

- Python 3.8+
- files-to-prompt library
- Interactive terminal
</file>
<file path="requirements.txt">
click>=8.0.0
rich>=10.0.0
inquirer>=2.8.0
openai>=1.0.0
requests>=2.25.0
</file>
<file path="setup.py">
#!/usr/bin/env python3

from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

setup(
    name="shotgun-terminal",
    version="0.1.0",
    author="Shotgun Code Team",
    description="Terminal version of Shotgun - Generate comprehensive project context for LLM workflows",
    long_description=long_description,
    long_description_content_type="text/markdown",
    packages=find_packages(),
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Developers",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
    ],
    python_requires=">=3.8",
    install_requires=[
        "click>=8.0.0",
        "rich>=10.0.0",
        "inquirer>=2.8.0",
        "openai>=1.0.0",
        "requests>=2.25.0",
    ],
    entry_points={
        "console_scripts": [
            "shotgun-terminal=shotgun_terminal.cli:main",
        ],
    },
)
</file>